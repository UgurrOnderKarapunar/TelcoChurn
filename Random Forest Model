import pandas as pd
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate
from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
import joblib
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Display ayarları
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)
pd.set_option('display.width', 1000)
pd.set_option('display.precision', 2)
pd.set_option('display.float_format', '{:.2f}'.format)
# Veri Yükleme
path = "/kaggle/input/telco-customer-churn"
df = pd.read_csv("/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv")
df.head()
df.drop("customerID",axis=1,inplace=True)


#### Functıon #####


def preprocess_and_train_rf(dataframe, target):
    #### Split X, y ####
    X = dataframe.drop(target, axis=1)
    y = dataframe[target]
    label = LabelEncoder()
    y = label.fit_transform(y)
    
    #### Identify categorical and numerical columns ####
    cat = X.select_dtypes(include="object").columns
    num = X.select_dtypes(include=["float", "int"]).columns
    print(f"Categorical Cols: {cat}")
    print(f"Numerical Cols: {num}")
    
    #### Identify and drop dominant categories ####
    doms_list = []
    for col in cat:
        doms = dataframe[col].value_counts(normalize=True)
        if doms.max() > 0.80:
            doms_list.append(col)
    
    if doms_list:
        X.drop(doms_list, axis=1, inplace=True)
        cat = X.select_dtypes(include="object").columns  
    
    #### Define preprocessing pipelines ####
    numerical_transformer = Pipeline(steps=[
        ('imputer', KNNImputer()),  
        ('scaler', RobustScaler())])
    
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), 
        ('onehot', OneHotEncoder(handle_unknown='ignore'))])
    
    #### Combine transformers into a preprocessor ####
    preprocessor = ColumnTransformer(transformers=[
        ('num', numerical_transformer, num),
        ('cat', categorical_transformer, cat)])
    
    #### Split data into training and testing sets ####
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
    
    #### Define the RandomForest model ####
    rf = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(random_state=42))
    ])
    
    #### Train the model ####
    rf.fit(X_train, y_train)
    
    #### Make predictions ####
    y_pred = rf.predict(X_test)
    
    #### Evaluate the model ####
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model Accuracy: {accuracy * 100:.2f}%")
    
     #### Save the trained model using joblib ####
    model_filename = 'random_forest_model.pkl'
    joblib.dump(rf, model_filename)
    print(f"Model saved as {model_filename}")
    return rf, X_train, X_test, y_train, y_test

# Example usage:
rf, X_train, X_test, y_train, y_test = preprocess_and_train_rf(df, 'Churn')
loaded_rf = joblib.load('random_forest_model.pkl')
print("Loaded model from disk.")
# Model Accuracy: 78.42%
